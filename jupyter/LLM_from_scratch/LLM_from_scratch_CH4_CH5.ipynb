{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e142834a-0312-4ad8-a897-24a657fa10e9",
   "metadata": {},
   "source": [
    "## 4.1 Coding an LLM architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20dd0169-668e-4426-9b68-5be63a618263",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257,\n",
    "# Vocabulary size\n",
    "\"context_length\": 1024,\n",
    "# Context length\n",
    "\"emb_dim\": 768,# Embedding dimension\n",
    "\"n_heads\": 12,# Number of attention heads\n",
    "\"n_layers\": 12,# Number of layers\n",
    "\"drop_rate\": 0.1,# Dropout rate\n",
    "\"qkv_bias\": False# Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9969887f-a746-4caf-bdf6-18ada915619e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 1024,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': False}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8392d53-3f5d-4a21-a2e7-6b690fca19bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    #C\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "    #D\n",
    "        return x\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    #E\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07e63751-4f59-4d61-b64e-6b061fc8197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(*[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]) #A\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        #B\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ebc736b-791a-4671-b6e4-493444234986",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cfc58ac-c58c-4f4c-9c94-384cb2351e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daa59876-6edd-449a-9141-cce383852b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), GELU(), nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),)\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26813cab-dcd4-4319-af0e-c3f42a8a7c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\tdef __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "\t\tsuper().__init__()\n",
    "\t\tassert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "\t\tself.d_out = d_out\n",
    "\t\tself.num_heads = num_heads\n",
    "\t\tself.head_dim = d_out // num_heads\n",
    "\t\t#A\n",
    "\t\tself.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\t\tself.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\t\tself.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\t\tself.out_proj = nn.Linear(d_out, d_out)\n",
    "\t\t#B\n",
    "\t\tself.dropout = nn.Dropout(dropout)\n",
    "\t\tself.register_buffer('mask',torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\tdef forward(self, x):\n",
    "\t\tb, num_tokens, d_in = x.shape\n",
    "\t\tkeys = self.W_key(x)#C\n",
    "\t\tqueries = self.W_query(x)#C\n",
    "\t\tvalues = self.W_value(x)#C\n",
    "\t\tkeys = keys.view(b, num_tokens, self.num_heads, self.head_dim) #D\n",
    "\t\tvalues = values.view(b, num_tokens, self.num_heads, self.head_dim) #D\n",
    "\t\tqueries = queries.view(b, num_tokens, self.num_heads, self.head_dim)#D\n",
    "\t\tkeys = keys.transpose(1, 2)#E\n",
    "\t\tqueries = queries.transpose(1, 2)#E\n",
    "\t\tvalues = values.transpose(1, 2)#E\n",
    "\t\tattn_scores = queries @ keys.transpose(2, 3)\n",
    "\t\t#F\n",
    "\t\tmask_bool = self.mask.bool()[:num_tokens, :num_tokens]#G\n",
    "\t\tattn_scores.masked_fill_(mask_bool, -torch.inf)#H\n",
    "\t\tattn_weights = torch.softmax(\n",
    "\t\tattn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\t\tattn_weights = self.dropout(attn_weights)\n",
    "\t\tcontext_vec = (attn_weights @ values).transpose(1, 2) #I\n",
    "\t\t#J\n",
    "\t\tcontext_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "\t\tcontext_vec = self.out_proj(context_vec)\n",
    "\t\t#K\n",
    "\t\treturn context_vec\n",
    "\n",
    "\n",
    "#A Reduce the projection dim to match desired output dim\n",
    "#B Use a Linear layer to combine head outputs\n",
    "#C Tensor shape: (b, num_tokens, d_out)\n",
    "#D We implicitly split the matrix by adding a `num_heads` dimension. Then we unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "#E Transpose from shape (b, num_tokens, num_heads, head_dim) to (b, num_heads, num_tokens, head_dim)\n",
    "#F Compute dot product for each head\n",
    "#G Mask truncated to the number of tokens\n",
    "#H Use the mask to fill attention scores\n",
    "#I Tensor shape: (b, num_tokens, n_heads, head_dim)\n",
    "#J Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "#K Add an optional linear projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec37061d-0016-4edf-a32f-c4b545f923ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(d_in=cfg[\"emb_dim\"], d_out=cfg[\"emb_dim\"], context_length=cfg[\"context_length\"], num_heads=cfg[\"n_heads\"],\n",
    "dropout=cfg[\"drop_rate\"], qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "    def forward(self, x):\n",
    "        #A\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        # Add the original input back\n",
    "        shortcut = x\n",
    "        #B\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        #C\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9ca2f54-ed5a-4a5b-839d-09eae40b2d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "#A\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97178ed2-bc96-49ce-bde0-d1a318ba9999",
   "metadata": {},
   "source": [
    "## 4.6 Coding the GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7afc679-6623-4356-a867-427c9f48b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        #A\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d27e8db9-76d2-4c60-afbd-cf3c1a1bb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size): #A\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        #B\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]#C\n",
    "        probas = torch.softmax(logits, dim=-1)#D\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)#E\n",
    "        idx = torch.cat((idx, idx_next), dim=1)#F\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db089043-d488-4603-8d4d-892a24ea6eca",
   "metadata": {},
   "source": [
    "## 5.1.1 Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a79d4221-55fb-45af-897b-82d8cef6d82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257,\n",
    "\"context_length\": 256,\n",
    "#A\n",
    "\"emb_dim\": 768,\n",
    "\"n_heads\": 12,\n",
    "\"n_layers\": 12,\n",
    "\"drop_rate\": 0.1,\n",
    "#B\n",
    "\"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73441028-2100-41dd-9aee-1eb5e92bd537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd1cf170-54a2-4741-8627-1b117c5575e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2840c8d2-56f8-4034-a513-3210d1164549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20480\n",
      "Tokens: 5146\n"
     ]
    }
   ],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa2e8bd8-32aa-4f3c-a3f7-f0ba3e971ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cac5873e-99e7-444e-b77d-8122313da7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    #A\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    #B\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=0)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd0cf75a-a63c-45df-b6d0-eb325ec3461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        token_ids = tokenizer.encode(txt)#A\n",
    "        for i in range(0, len(token_ids) - max_length, stride):#B\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    def __len__(self):\n",
    "        #C\n",
    "        return len(self.input_ids)\n",
    "    def __getitem__(self, idx):\n",
    "        #D\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e4592f2-2e46-4c76-92a4-087747f6f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "947f0e57-e2df-42b3-8d18-f1769a0c8199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84edbf5a-f2e2-4939-8550-d6f2fb46e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device) #A\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65babd85-566b-4599-a457-0a69db751eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "        #A\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "        #B\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "            #C\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "    #D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e5fb9c2-0fb0-4163-a28f-f41144968bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Training loss: 10.987582842508951\n",
      "Validation loss: 10.983160018920898\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #A\n",
    "print(device)\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    #B\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    #C\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a0c2e70-538e-4261-ad7e-afb8736da900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    #A\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    for epoch in range(num_epochs):\n",
    "        #B\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            #C\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()#D\n",
    "            optimizer.step()#E\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            if global_step % eval_freq == 0:\n",
    "                #F\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "        generate_and_print_sample(\n",
    "        #G\n",
    "            model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5459c1e5-87fe-41b7-bdec-714a90a0ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()#A\n",
    "    with torch.no_grad():#B\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b305f9ab-22b7-42cc-9226-c3d12be47d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model=model, idx=encoded, max_new_tokens=50, context_size=context_size)\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))\n",
    "        # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f842b7ae-276a-4f6f-9dc9-bba5cd08406f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 10.060, Val loss 9.928\n",
      "Ep 1 (Step 000005): Train loss 8.158, Val loss 8.339\n",
      "Every effort moves you,.                                                \n",
      "Ep 2 (Step 000010): Train loss 6.556, Val loss 7.052\n",
      "Ep 2 (Step 000015): Train loss 5.926, Val loss 6.601\n",
      "Every effort moves you, and,, and,, and,,,, and,.                                   \n",
      "Ep 3 (Step 000020): Train loss 5.823, Val loss 6.501\n",
      "Ep 3 (Step 000025): Train loss 5.391, Val loss 6.382\n",
      "Every effort moves you, and to the of the of the of the, and I had. Gis, and, and, and, and, and, and I had, and, and, and, and, and, and, and, and, and,\n",
      "Ep 4 (Step 000030): Train loss 4.594, Val loss 6.280\n",
      "Ep 4 (Step 000035): Train loss 5.016, Val loss 6.293\n",
      "Every effort moves you, I had.    \"I had been.               \"I\"I the picture\"I had the the honour of the picture and I had been.  \n",
      "Ep 5 (Step 000040): Train loss 4.119, Val loss 6.158\n",
      "Every effort moves you know the                                                \n",
      "Ep 6 (Step 000045): Train loss 4.018, Val loss 6.183\n",
      "Ep 6 (Step 000050): Train loss 2.875, Val loss 6.158\n",
      "Every effort moves you know the fact, and pushed one of the to the fact of the last I had been his own, with the fact, and that, I had been his pictures--I had the donkey.           \n",
      "Ep 7 (Step 000055): Train loss 3.085, Val loss 6.157\n",
      "Ep 7 (Step 000060): Train loss 2.102, Val loss 6.112\n",
      "Every effort moves you know,\" was not that the picture for a smile that he had the last word.     \"I didn't you know. \"--as Jack himself at the donkey. \" his pictures--and--because he was his pictures\n",
      "Ep 8 (Step 000065): Train loss 1.973, Val loss 6.152\n",
      "Ep 8 (Step 000070): Train loss 1.363, Val loss 6.228\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word. Gisburn's an awful simpleton, and Mrs. Gisburn's an them at my elbow and as he had been the man of the hour. The\n",
      "Ep 9 (Step 000075): Train loss 1.239, Val loss 6.204\n",
      "Ep 9 (Step 000080): Train loss 0.833, Val loss 6.256\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"    \"--it was back his head to look up at the honour being _mine_--because he's the first\n",
      "Ep 10 (Step 000085): Train loss 0.599, Val loss 6.368\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1) #A\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "model, train_loader, val_loader, optimizer, device,\n",
    "num_epochs=num_epochs, eval_freq=5, eval_iter=1,\n",
    "start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fb6b37d-bc6d-42d4-a926-5509720eb971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax2 = ax1.twiny()#A\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)#B\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be71edf9-f1be-47dd-a940-0aefcffedeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(model=model, idx=text_to_token_ids(\"Every effort moves you\", tokenizer), max_new_tokens=25, context_size=GPT_CONFIG_124M[\"context_length\"])\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7849b8af-d767-4f09-bb0b-cb48f5ec5555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
